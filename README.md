# Speech-Emotion-Recognition
<B>Introduction</B>

Speech is the fundamental strategy for us to communicate with each other. However,
emotions play a vital role in communication. It is a medium of expression of oneâ€™s
perspective to others. It includes several emotions such as anger, happiness,
sadness, fear, passion, disgust, etc. It has been a topic of research for a long time
but it is a challenging task to perform as human emotions are very subjective and
sometimes it is even harder for humans to notate them.
The main aim of this project is to classify the emotional state of the speaker from the
speech signal. In this, we will be making SER (Speech Emotion Recognition) which
identifies speech signals to detect the emotions underlying them. In particular, we will
be creating a classification model elicited by speeches based on Deep Learning and
Machine Learning algorithms ie. (MLP classification, CNN classifiers, SVM) by
analyzing the acoustic features.

<B>Database Used</B>

The portion of the RAVDESS contains 2880 files: 60 trials per actor x 24 actors = 2880. The RAVDESS contains 24 professional actors (12 female, 12 male), vocalizing two lexically-matched statements in a neutral North American accent, fearful, surprise, and disgust  expressions. Each expression is produced at tro levels of emotional intensity (normal, strong), with an additional neutral expression.

<B>IDEOLOGY BEHIND THE PROJECT</B>

The idea behind creating this project was to build a machine learning that could detect emotions from the speech we have with each other all the time.
So, why not have an emotion detector that will gauge your emotions and in the future recommend different things based on your mood. This can be used by multiple industries to offer different services like marketing companies suggesting you buy products based on your emotions, the automotive industry can detect the emotions and adjust the speed of autonomous cars as required to avoid any collisions etc.

